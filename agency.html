<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="favicon.ico">

    <title>MOCORE | Cognitive Agency</title>
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Oswald:300,400,500|Roboto:100,300,400,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Poppins&display=swap" rel="stylesheet">
    <link href="assets/css/bootstrap.css" rel="stylesheet">
    <link href="assets/css/header.css" rel="stylesheet">
 
</head>

<body>
    <nav class="navbar navbar-expand-md navbar-dark fixed-top" name="top">
        <a class="navbar-brand" href="index.html"><img src="" height="30px;"></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExampleDefault" aria-controls="navbarsExampleDefault" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="navbar-collapse collapse" id="navbarsExampleDefault">
            <ul class="navbar-nav mr-auto">
                <li class="nav-item">
                    <a class="nav-link" href="/index.html">Home</a>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                      Research
                    </a>
                        <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                          <a class="dropdown-item" href="/research.html">Research Home</a>
                          <div class="dropdown-divider"></div>
                          <a class="dropdown-item" href="/agency.html">Cognitive Factors</a>
                          <a class="dropdown-item" href="/sensory_feedback.html">Sensory Feedback</a>
                          <a class="dropdown-item" href="/surreal_vr.html">Surreal VR</a>
                        </div>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                      Education
                    </a>
                        <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                          <a class="dropdown-item" href="/virtual_reality.html">Virtual Reality - High School</a> 
                        </div>
                </li>  
                <li class="nav-item">
                    <a class="nav-link" href="/people.html">People</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/events.html">News</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/publications.html">Publications</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/presentations.html">Presentations</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link nav-link-end" href="/contact.html">Contact</a>
                </li>
            </ul>
        </div>
    </nav>
    <main role="main">
        <div class="header_agency header_sub">
            <div class="container">
                <div class="row">
                    <div class="offset-md-2 col-md-8 header_text">
                        <h1>Leverage Cognitive Factors for Rehabilitation and Movement Training</h1>
                    </div>
                </div>
            </div>
        </div>

        <section id="section_01" style="text-align: center;">
            <div class="container">
                <div class="row">
                    <div class="col-md-12">
                        <h4>Our objective is to investigate the potential role of cognitive factors</br>
                        in movement training and leverage them to optimize upper-extremity rehabilitation</h4>
                    </div>
                </div>
                <div class="col-md-7">
                </div>
            </div>
        </section>
<section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Cognition Expectations in VR Reach Training</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-6">
                        <p>
                            In this experiment, participants complete a reaching task in a virtual environment with the goal of tracing a sinusoid shape. 
                            Coins appear adjacent to the sinusoid path, and participants must perform rapidly dynamic shifts with their hands to collect the coins and return to the sinusoid. 
                            The coins appear either with the sinusoid prior to the start of a trial (proactive training) or appear unexpectedly in progressive sequence while participants trace the sinusoid (reactive training).  
                            Motor performance is measured by the ability to accurately trace the sinusoid shape and collect the coins. 
                            This project’s goal is to examine how alteration of cognitive processing in relation to the “expectation” of dynamic task requirements (i.e., collecting the coins) will affect steady-state motor tasking (i.e., sinusoid tracing). 
                        </p>
                    </div>
                    <div class="col-md-3">
                        <img src="/assets/images/research/agency/SinusoidCoins.png" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                    </div>
                     <div class="col-md-3">
                        <img src="/assets/images/research/agency/SinusoidReach.png" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                    </div>
                    <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/agency/IMG_8855.mp4" type="video/mp4"></video>
                </div>
                </br>
            </div>
        </section>

        
    <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Cognition Glove with Virtual Reality</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-8">
                        <p>
                            The preliminary study presented a novel method to predict and inform secure grasp while wearing a sensor glove during a grasp-move-place task. Also, we investigated the effect of providing sensory feedback on grasp performance with consideration of agency. 
                            In this study, we further examined the training effect and integrated the sensor glove with VR immersion. VR platforms were used widely in movement rehabilitation studies due to its advantage in customization, cost-effectiveness and ability to provide augmented feed-back. 
                            We hypothesized that the training effect would be greater with the VR immersion than our preliminary results. We are currently analyzing able-bodied results and testing with clinical participants (TBI and incomplete SCI pa-tients) to compare the results of this study.
                            The ultimate goal is to develop a mixed-reality rehabilitative training paradigm that provide customizable and augmented feedback to improve grasp performance while leverag-ing agency for individuals following neurotrauma.
                        </p>
                    </div>
                    <div class="col-md-4">
                        <img src="/assets/images/research/agency/CGlove_VR_photo.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                    </div>
                </div>
                </br>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row collaborators">
                            <div class="col-md-7">
                                <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/agency/CGlove_VR_video.mp4" type="video/mp4"></video>
                            </div>
                            <div class="col-md-5">
                                <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/agency/TBIvid.mov" type="video/mp4"></video>
                            </div>
                        </div>
                    </div>
                </section>
                <div class="col-md-12" style="text-align: center">
                        <h3><b>SCI and TBI Clinical Participants</b></h3></br></br>
                    </div>
            </div>
        </section>
    
        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Cognition Glove</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-12">
                        <p>
                            In this project, we developed a sensor glove that effectively predicts secure grasp with force/flex data from the glove and improves grasp performance for a grasp-move-place task. We implemented a machine learning
                            algorithm that predicts secure grasp with higher accuracy than previous analytical methods. The Cognition Glove is also coupled with grasp task completion to sensory sequences, including visual, audio, and haptic feedback. We aim to reverse-engineer the sense of agency, where we produce a paradigm to modulate motion control
                            performance to achieve a better sense of agency and improve movement outcome. Our preliminary results showed that training with agency-inspired feedback significantly improved grasp performance including completion time
                            and path-length [4]. This correlation between motor performance and sense of agency will be applied for benefiting neuro-motor rehabilitation for SCI, TBI and stroke patients.
                        </p>
                    </div>
                </div>
                </br>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row">
                            <div class="col-md-6">
                                <img width = "79%" src="/assets/images/research/agency/CGlove_component.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                            </div>
                            <div class="col-md-6">
                                <img width = "71%" src="/assets/images/research/agency/CGlove_experiment setup.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                            </div>
                        </div>
                    </div>
                </br>
                </section>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row">
                        <div class="col-md-12">
                        <img width = "90%" src="/assets/images/research/agency/CGlove_experiment.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                        </div>
                </section>
            </div>
        </section>

           
        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Role of Agency in Hand Reach and Grasp Rehabilitation</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-12">
                        <p>
                            The goal of this project is to investigate the role of sense of agency, which represents the perception of self-control, in reach and grasp tasks for neurotrauma rehabilitation purposes. In this
                            project, we aim to explicitly monitor sense of agency and identify the correlation between agency and movement performance. The results indicated the positive correlation between agency and movement performance in force pinch [1] and reach grasp task [2]. This project will be clinical relevant for hand prostheses training after SCI or upper-limb amputation and providing
                            better virtual reality environments to accelerate post-stroke motor-relearning.
                        </p></br>
                        <div class="col-md-12" style="text-align: center">
                            <h3><b>Reach Pinch Task</b></h3></br></br>
                        </div>
                    </div>
                    <section id="section_01" style="text-align: center; margin:0;">
                        <div class="container">
                            <div class="row">
                                <div class="col-md-6">
                                    <img width = "85%" src="/assets/images/research/agency/Pinch_photo.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                                </div>
                                <div class="col-md-6">
                                    <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/agency/Pinch_video.mp4" type="video/mp4"></video>
                                </div>
                            </div>
                        </div>
                    </section>
                    <div class="col-md-12" style="text-align: center">
                        </br></br>
                        <h3><b>Hand Grasp Task</b></h3></br></br>
                    </div>
                    <section id="section_01" style="text-align: center; margin:0;">
                        <div class="container">
                            <div class="row">
                                <div class="col-md-6">
                                    <img width = "85%" src="/assets/images/research/agency/Reach_photo.JPG" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                                </div>
                                <div class="col-md-6">
                                    <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/agency/Reach_video.mp4" type="video/mp4"></video>
                                </div>
                            </div>
                        </div>
                    </section>
                </div>
            </div>
        </section>

        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Hand Reach and Grasp Combined With Electroencephalography(EEG)</br>
                        & Electromyography(EMG)</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-12">
                        <p>
                            In this project, we aim to investigate the relationship between sense of agency and EEG/EMG signals. The subjects performed hand-grasp or force-pinch task while EEG/EMG signals were
                            measured from different brain regions/muscle sites that are associated with agency and readiness potential/muscle acitivity. Our results indicate a positive R-relationship between agency and increased beta band apparent. With further analysis we aim to
                            develop EEG/EMG-based automated procedure for adapting prosthesis control with better sense of agency and movement control.
                        </p>
                    </div>
                </div>
                </br>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row">
                            <div class="col-md-6">
                                <img width = "80%" src="/assets/images/research/agency/eeg4.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                            </div>
                            <div class="col-md-6">
                                <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/agency/Pinch_EEG_EMG.mp4" type="video/mp4"></video>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </section>

        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Virtual Reality Hand-Reach With Reward Feedback</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-8">
                        <p>
                            In this project, we aim to study the relationship between the sense of agency and visual feedback. Specifically, the visual feedback as a bi-modal knowledge of reward and penalty based on motion performance. The study was
                            performed with a hand-reach task in a virtual reality environment. Motion performance metrics included speed, accuracy and path-length. Our preliminary results show that the 'reward feedback' improves sense of agency and
                            path-length [3].
                        </p>
                    </div>
                    <div class="col-md-4">
                        <img src="/assets/images/research/agency/Reward_photo.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                    </div>
                </div>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row">
                            <div class="col-md-6">
                                <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/agency/Reward Protocol Positive Feedback.mp4" type="video/mp4"></video>
                            </div>
                            <div class="col-md-6">
                                <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/agency/Reward Protocol Negative Feedback.mp4" type="video/mp4"></video>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </section>

        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Virtual Reality Agency Tuning With Multi-Degree of Freedom System</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-12">
                        <p>
                            In this project, our goal is to investigate a multi degree-of-freedom (DOF) device's tuning according to sense of agency. We hypothesize that the operation in each DOF could be uniquely tuned according to the user's
                            optimal sense of agency. A device is tuned based upon user-specific optimal parameters and performance is measured in a motion task. We also aim to investigate the point-of-interface difference between a 6-DOF Steward
                            platform (that can physically translate and rotate) to a 6-DOF space mouse. We hypothesize that the Steward platform with additional point-of interface DOF should help user to produce greater proprioceptive involvement
                            and achieve better agency tuning.
                        </p>
                    </div>
                </div>
                </br>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row">
                            <div class="col-md-6">
                                <img src="/assets/images/research/agency/joystick-picture.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                            </div>
                            <div class="col-md-6">
                                <img src="/assets/images/research/agency/picture2.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </section>

        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h5 class="subpage_header">References</h5>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators" style="margin-top:50px;">
                    <div class="col-md-12">
                        <p>
                            1. ​R Nataraj, S Sanford, “Control Modifications of Grasp Force Covaries Agency and Performance on Rigid and Compliant Surfaces,” Frontiers in Bioengineering and Biotechnology, January 2021, doi: 10.3389/fbioe.2020.574006.​
                        </p>
                        <p>
                            2. ​R Nataraj, S Sanford, A Shah, M Liu, “Agency and Performance of Reach-to-Grasp With Modified Control of a Virtual Hand: Implications for Rehabilitation,” Frontiers in Human Neuroscience, vol. 14, 2020, doi: 10.3389/fnhum.2020.00126.​
                        </p>
                        <p>
                            3. ​R Nataraj, D Hollinger, M Liu, A Shah, “Disproportionate positive feedback facilitates sense of agency and performance for a reaching movement task with a virtual hand,” PLoS ONE, 15(5): e0233175, 2020, doi: 10.1371/journal.pone.0233175.​
                        </p>
                        <p>
                            4. ​M Liu, S Wilder, S Sanford, S Saleh, N Harel, R Nataraj, “Training with Agency-Inspired Feedback from an Instrumented Glove to Improve Functional Grasp Performance,” Sensors, February 2021, doi: 10.3390/s21041173.
                        </p>
                    </div>
                </div>
            </div>
        </section>

    </main>

    <section class="vin_footer">
        <footer class="container">
            <div class="row">
                <div class="col-md-4">
                    <p>© 2019 MOCORE Laboratory</p>
                </div>
                <div class="col-md-8" style="text-align:right">
                    <p style="padding-top:15px"><a class="btn btn-primary btn-lg card_btn" href="#top" role="button">Back to top</a></p>
                </div>
            </div>
        </footer>
    </section>

    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="assets/js/bootstrap.min.js"></script>
</body>

</html>
