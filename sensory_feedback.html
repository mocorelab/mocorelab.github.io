<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="favicon.ico">

    <title>MOCORE | Sensory Feedback</title>
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Oswald:300,400,500|Roboto:100,300,400,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Poppins&display=swap" rel="stylesheet">
    <link href="assets/css/bootstrap.css" rel="stylesheet">
    <link href="assets/css/header.css" rel="stylesheet">

</head>

<body>
    <nav class="navbar navbar-expand-md navbar-dark fixed-top" name="top">
        <a class="navbar-brand" href="index.html"><img src="" height="30px;"></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExampleDefault" aria-controls="navbarsExampleDefault" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="navbar-collapse collapse" id="navbarsExampleDefault">
            <ul class="navbar-nav mr-auto">
                <li class="nav-item">
                    <a class="nav-link" href="/index.html">Home</a>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                      Research
                    </a>
                        <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                          <a class="dropdown-item" href="/research.html">Research Home</a>
                          <div class="dropdown-divider"></div>
                          <a class="dropdown-item" href="/agency.html">Cognitive Agency</a>
                          <a class="dropdown-item" href="/sensory_feedback.html">Sensory Feedback</a>
                        </div>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                      Education
                    </a>
                        <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                          <a class="dropdown-item" href="/virtual_reality.html">Virtual Reality - High School</a>
                          <a class="dropdown-item" href="/virtual_reality_adv.html">Virtual Reality - MOCORE</a>
                        </div>
                </li>  
                <li class="nav-item">
                    <a class="nav-link" href="/people.html">People</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/events.html">News</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/publications.html">Publications</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/presentations.html">Presentations</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link nav-link-end" href="/contact.html">Contact</a>
                </li>
            </ul>
        </div>
    </nav>
    <main role="main">
        <div class="header_vf header_sub">
            <div class="container">
                <div class="row">
                    <div class="offset-md-2 col-md-8 header_text">
                        <h1>Multi-Sensory Feedback for Myoelectric Control</h1>
                    </div>
                </div>
            </div>
        </div>

        <section id="section_01" style="text-align: center;">
            <div class="container">
                <div class="row">
                    <div class="col-md-12">
                        <h4>Our objective is to investigate novel multi-sensory feedback approaches</br>
                        to improve muscle control for greater independent function or better control of a myoelectric assistive device</h4>
                    </div>
                </div>
            </div>
        </section>

        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Isometric Muscle Control of a Virtual Myoelectric Prosthetic</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-12">
                        <p>
                        Using a machine-learning algorithm, isometric muscle activity is mapped to directional intent for controlling a virtual myoelectric prosthetic.
                            A transparent arm helps guide the participant by displaying the shortest path length between targets. The photo below is of a clinical participant 
                            with SCI completing our brace protocol at the VA hospital. 
                        </p>
                    </div>
                </div>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row collaborators">
                            <div class="col-md-8">
                                </br></br>
                                <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/vf/Continuous_Trim.mp4" type="video/mp4"></video>
                            </div>
                            <div class="col-md-4">
                                </br></br>
                                <img src="/assets/images/SCI_1.JPG" style="border-style: solid; border-width: 2px;"></img></br></br></br>                            
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </section>
    
        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Upper-body Restrictive Brace for Virtual Reality Rehabilitation</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-12">
                        <p>
                        The major platform for our multi-sensory feedback research is an upper-body restrictive brace that integrates with a virtual reality environment.
                            The brace is designed to restrict motion at the elbow and shoulder in any desired arm position for isometric muscle training. Isometric
                            muscle training is used following neurotrauma and improves independent function (after the brace is removed) or myoelectric control 
                            of a remote device (prosthetic, teleoperation). The brace is designed in a Computer Aided Design program (LEFT) and can be ported over 
                            into a virtual reality environment (RIGHT) to demo how the electromyography sensors (RIGHT, red) and
                            vibration motors (RIGHT, blue) would properly integrate with the brace.
                        </p>
                    </div>
                </div>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row">
                            <div class="col-md-12">
                                </br></br>
                                <img src="/assets/images/research/vf/FullFigure3.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </section>
    
        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Visual and Haptic Feedback for Virtual Reality Based Isometric Training</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-12">
                        <p>
                        While donning the restrictive upper-body brace, subjects control a virtual prosthetic to complete a point-to-point reaching task.
                            Visual feedback is provided as a 'ghost-arm' that is an identical representation of the subjects prosthetic but presented in a 
                            transparent material that follows the shortest path between the starting position and desired target. Vibrotactile feedback can
                            guide subject position relative to the shortest path by mapping vibration magnitude to position error magnitude. 
                            Vibration can also alter neurophysiological signals and user proprioception for more cognitive-based approaches to improve muscle control.
                        </p>
                    </div>
                </div>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row">
                            <div class="col-md-12">
                                </br></br>
                                <img src="/assets/images/research/vf/BracePhoto2.jpg" style="border-style: none; border-width: 2px;"></img></br></br></br>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </section>
    
    <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Machine-Learning Classification of Reduced Muscle Sets</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-8">
                        <p>
                            A virtual reality task was developed that required subjects to induce isometric muscle activity for controlling an object through a 2D maze.
                            Different machine-learning classifiers, ranging from linear discriminant analysis to neural networks, were developed for mapping
                            electromyography activity to directional intent. Additionally, multiple reduced muscle sets were evaluated by reducing the number of 
                            electromyography inputs into the classifiers to 'replicate' neurological disorders or neurotrauma. The combination of various muscle sets
                            and various reduced muscle sets were evaluated for the effects on task performance (completion time, number of wall collisions) and 
                            classification accuracy.
                        </br></br>
                            K Walsh et al., February 2021, doi: 10.1016/j.bspc.2021.102487.
                        </p>
                    </div>
                    <div class="col-md-4">
                        <img src="/assets/images/research/vf/VisualFeedback3.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                    </div>
                </section>
            </div>
        </section>
    
        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Visual Feedback for Rehabilitation and Movement Assistance Training</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-12">
                        <p>
                            Visual feedback (VF) can be presented in a myriad of modes, depending on the timing, style of display, and performance metric objectively targeted. VF outperforms audio and haptic feedback for training user spatial
                            positioning of complex motor-tasks [Sigrist 2013]. Our interests are in developing VF paradigms that effectively train the user to complete a dynamic rehabilitation task for more effective assist device control.
                        </p>
                    </div>
                </div>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row">
                            <div class="col-md-4">
                                </br></br>
                                <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/vf/Motion_Capture.mp4" type="video/mp4"></video>
                                <i>Optitrack Motion Capture Analysis</i></br>
                                <sub>Retroreflective marker position are captured by infrared cameras for tracking user spatial positioning</sub>
                            </div>
                            <div class="col-md-4">
                                </br></br>
                                <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/vf/Concurrent_VF.mp4" type="video/mp4"></video>
                                <i>Concurrent Visual Feedback</i></br>
                                <sub>Real-time feedback of a performance metric while the user completes the task</sub>
                            </div>
                            <div class="col-md-4">
                                </br></br>
                                <video style="border-style: solid; border-width: 2px;" width="100%" controls><source src="/assets/videos/vf/Terminal_VF.mp4" type="video/mp4"></video>
                                <i>Terminal Visual Feedback</i></br>
                                <sub>Feedback presented immediately following task-completion </sub>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </section>

        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Visual Feedback Training for a Two-legged Squat Exercise</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-12">
                        <p>
                            VF was presented in a variety of forms for training the subjects on a dynamic rehabilitation task. The objective was to determine the visual feedback mode with the greatest reduction in movement error over a single
                            training session. The winning VF trained the greatest consistency of spatial positioning and muscle activation patterns.
                        </br></br>
                            S Sanford et al., February 2021, doi: 10.1123/jsr.2020-0234.
                        </br></br>
                            S Sanford et al., May 2020, doi: 10.1080/00222895.2020.1770670.
                        </p>
                    </div>
                </div>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row">
                            <div class="col-md-8">
                                </br></br>
                                <img src="/assets/images/research/vf/VFsquatannotated.jpg" style="border-style: none; border-width: 2px;"></img></br></br></br>
                            </div>
                            <div class="col-md-4">
                                </br></br>
                                <img src="/assets/images/research/vf/complex-continuous.jpg" style="border-style: solid; border-width: 2px;"></img></br></br></br>
                                <i>Continuous Complex Visual Feedback</i></br>
                                <sub>An example of a VF presented for the squat exercise. Categorized as 'Continuous Complex', the user's spatial positioning (black) of the shank, thigh, and torso segments, are simultaneously displayed with the target trajectory (red). As the subject squats his objective is to reduce the error between their spatial position and the target position.</sub>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </section>

        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h3 class="subpage_header">Rectus Femoris Muscle Activation Influenced by Changes in Squat Technique</h3>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-12">
                        <p>
                            The two legged squat exercise is clinically correlated to the sit-to-stand movement. Muscle activation patterns are highly influenced by technique and are captured in real-time by surface electromyography sensors on
                            lower-limb muscles primarily responsible for force generation. Training the user to do a complex rehabilitation task in a more consistent movement pattern will induce consistent muscle activation patterns. </br></br>
                            The video below is a demonstration of electromyography activity of the left and right rectus femoris muscles during different depths
                            of the two-legged squat exercise. Our objective is to evaluate different visual feedback features for optimizing movement rehabilitation training.
                        </p>
                    </div>
                </div>
                <section id="section_01" style="text-align: center; margin:0;">
                    <div class="container">
                        <div class="row">
                            <div class="col-md-12">
                                </br></br>
                                <video width="100%" controls><source src="/assets/videos/vf/Squat.mp4" type="video/mp4"></video>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </section>

        <section id="section_01">
            <div class="container">
                <div class="row collaborators">
                    <div class="col-md-1">
                        <hr class="section_divider">
                    </div>
                    <div class="col-md-11">
                        <h5 class="subpage_header">References</h5>
                        <hr class="section_divider">
                    </div>
                </div>
                <div class="row collaborators">
                    <div class="col-md-12">
                        <p>
                            1. S Sanford, M Liu, T Selvaggi, R Nataraj, “Effects of Visual Feedback Complexity on the Performance of a Movement Task for 
                            Rehabilitation,” Journal of Motor Behavior, May 2020, doi: 10.1080/00222895.2020.1770670.
                            </br>
                            2. S Sanford, M Liu, R Nataraj, “Concurrent Continuous Versus Bandwidth Visual Feedback With Varying Body Representation 
                            for the 2-Legged Squat Exercise,” Journal of Sport Rehabilitation, February 2021, doi: 10.1123/jsr.2020-0234.
                            </br>
                            3. R Sigrist, G Rauter, R Riener, P Wolf, “Augmented visual, auditory, haptic, and multimodal feedback in motor learning: 
                            a review,” Psychon. Bull. Rev., vol. 20, no. 1, pp. 21–53, Feb. 2013.
                            </br>
                            4. K Walsh, S Sanford, B Collins, N Harel, R Nataraj, “Performance potential of classical machine learning and deep 
                            learning classifiers for isometric upper-body myoelectric control of direction in virtual reality with reduced muscle 
                            inputs,” Biomedical Signal Processing and Control, February 2021, doi: 10.1016/j.bspc.2021.102487.
                        </p>
                    </div>
                </div>
            </div>
        </section>

    </main>

    <section class="vin_footer">
        <footer class="container">
            <div class="row">
                <div class="col-md-4">
                    <p>© 2019 MOCORE Laboratory</p>
                </div>
                <div class="col-md-8" style="text-align:right">
                    <p style="padding-top:15px"><a class="btn btn-primary btn-lg card_btn" href="#top" role="button">Back to top</a></p>
                </div>
            </div>
        </footer>
    </section>

    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="assets/js/bootstrap.min.js"></script>
</body>

</html>
